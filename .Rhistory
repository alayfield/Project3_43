x[-2]
x[-2][5]
(1:5)[c(FALSE, TRUE, TRUE, FALSE, TRUE)]
iq <- rnorm(12, mean = 100, sd = 15)
iq <- round(iq)
iq
iq > 105
iq > 125
iq[iq > 105]
sum(iq) / 12
ages <- c("bob" = 39, "carol" = 31, "ted" = 31, "alice" = 32)
ages
ages <- c(bob = 39, carol = 31, ted = 31, alice = 32)
ages
names(ages)
naems(iq)
names(iq)
names(iq) = c(jon, greg, amy)
names(iq) = c("John", 'Amy', "Sam", "Greg", "Fred", "Clint", "Camille", "Charlie", "Frank", "Alice", "Harry", "David")
iq
iq[iq>105]
iq[iq>100]
names(iq)
set.seed(6656)
iq <- rnorm(50000, mean = 100, sd = 15)
iq <- round(iq)
length(iq > 131)
iq > 131
iq > 131 == TRUE
(iq > 131) == TRUE
iq[iq > 131]
length(iq[iq>131])
.Machine$double.eps
set.seed(6656)
iq <- rnorm(50000, mean = 100, sd = 15)
iq <- round(iq)
length(iq[iq>131])
install.packages("tidyverse")
angle <- seq(from = 0, to = 180, by = 30)
angle
round(sin(angle * pi / 180), 3)
deg_to_rad <- function(x) x * (pi / 180)
angle
def_to_rad(angle)
deg_to_rad(angle)
incr <- function(x, by = 1) x + by
incr(1:5)
inc(1:5, by = 3)
incr(1:5, by = 3)
as.character(1:3)
paste("q", 1:3, sep = "_")
dnorm(x, mean = 0, sd = 1, log = FALSE)
x <- rnorm(30, mean = 100, sd = 15)
quantile(x, probs = c(0.25, 0.75))
median(x)
IQR(x)
hist(x)
x <- rnorm(30, mean = 100, sd = 15)
hist(x)
IQR(x)
median(x)
quantile(x, probs = c(0.25, 0.75))
t.test(mu=100)
t.test(x, mu=100)
x <- rnorm(300, mean = 100, sd = 15)
hist(x)
t.test(x, mu=100)
y <- rnorm(30, mean = 100, sd = 15)
hist(y, freq = FALSE, main = "")
curve(dnorm(x, mean = mu, sd = sigma), ylab = "Density", add = TRUE)
mu = 100
sigma = 15
curve(dnorm(x, mean = mu, sd = sigma), ylab = "Density", add = TRUE)
par(opar)
opar <- par(mar = c(5.1, 4.1, 1.1, 0.1))
dx <- hist(y, plot = FALSE)
ylim <- c(0, max(c(dnorm(mu, mean = mu, sd = sigma), dx$density)))
xlim <- range(c(qnorm(c(.0001, 0.999), mean = mu, sd = sigma), dx$breaks))
plot(dx, freq = FALSE, xlim = xlim, ylim = ylim, main = NULL)
curve(dnorm(x, mean = mu, sd = sigma), ylab = "Density", add = TRUE)
par(opar)
x <- runif(5) : y <- runif(5)
x <- runif(5) ; y <- runif(5)
x
y
v <- x < y
w <- x >= 1/2
v
w
!v
v | w
v & w
xor(v, w)
(v | w) & !(v & w)
x <- runif(100000) ; y <- runif(100000)
theta <- atan(y / x)
theta[0:5]
x[0:5]
y[0:5]
atan(y[1] / x[1])
atan(y[1] / x[1]) * (180/pi)
theta <- atan(y/x) * (180/pi)
theta[0:5]
his(theta, frequency=FALSE)
hist(theta, frequency=FALSE)
hist(theta)
hist(theta, frequency=FALSE, main="")
mu <- mean(theta)
sigma <- sd(theta)
quantiles <- qnorm(c(0.20, 0.80), mean = mu, sd = sigma)
x <- runif(100000) ; y <- runif(100000)
x <- runif(100000) ; y <- runif(100000)
theta <- atan(y / x) * (180 / pi)
x <- runif(100000) ; y <- runif(100000)
set.seed(010)
set.seed(010)
x <- runif(100000) ; y <- runif(100000)
theta <- atan(y / x) * (180 / pi)
# Question 2
# a
hist(theta, frequency=FALSE, main="")
# Question 3
# a
mu <- mean(theta)
# b
sigma <- sd(theta)
# c
quantiles <- qnorm(c(0.20, 0.80), mean = mu, sd = sigma)
x <- runif(100000) ; y <- runif(100000)
theta <- atan(y / x) * (180 / pi)
# Question 2
# a
hist(theta, frequency=FALSE, main="")
# Question 3
# a
mu <- mean(theta)
# b
sigma <- sd(theta)
# c
quantiles <- qnorm(c(0.20, 0.80), mean = mu, sd = sigma)
#Question 4
set.seed(010)
x <- runif(100000) ; y <- runif(100000)
theta <- atan(y / x) * (180 / pi)
# Question 2
# a
hist(theta, frequency=FALSE, main="")
# Question 3
# a
mu <- mean(theta)
# b
sigma <- sd(theta)
# c
quantiles <- qnorm(c(0.20, 0.80), mean = mu, sd = sigma)
#Question 4
#Question 4
#Question 4
Y <- c(FALSE, FALSE TRUE FALSE)
y <- c(FALSE, FALSE, TRUE, FALSE)
all(xor(x, y) & (x & y))
x <- c(TRUE, TRUE, FALSE, FALSE)
y <- c(FALSE, FALSE, TRUE, FALSE)
all(xor(x, y) & (x & y))
update.packages(ask = FALSE)
update.packages(ask = FALSE)
matrix(1:6, nrow = 2)
cbind(1:3, 3:1)
rbind(1:3, 3:1)
X <- matrix(1:4, nrow = 2)
X
apply(X, 2, prod)
X <- matrix(1:6, ncol = 2) ; Y <- matrix(1:6, ncol = 2)
X * Y
dim(X * Y)
dim(x)
dim(X)
X <- matrix(1:6, ncol = 2) ; Y <- matrix(1:6, nrow = 2)
X %*% Y
X
Y
X <- matrix(1:4, nrow = 2)
diag(solve(X) %*% X)
solve(X)
x <- c(1, 2, 3, 4, "a", "b", "c")
y <- c(5, 6, 7, 8, "d", "e", "f")
x + y
z <- c(x, y)
f <- c(c(x), c(y))
f
list(x, y)
f <- list(x, y)
f
f[1]
f[1][1]
f[[1]][1]
f[[2]][4]
f[[1]][c(1, 3, 5)]
x <- c(1, 1, 0, 0, 1)
y <- c(0, 1, 1, 1, 0)
all(xor(x, y) & (x & y))
x <- list(title = "The Big Lebowski", rottentomatoes = c(tomatometer = 82, audience = 94))
x[["rottentomatoes"]][1]
x["rottentomatoes"][[1]][1]
x["rottentomatoes"][[1]]
x["rottentomatoes"][1]
x$rottentomatoes[1]
array(1:3, c(2,4))
f <- array(1:3, c(2,4))
select(f, 1, 2)
f[, c(3, 1, 2)]
g <- array(1:3, c(5,4))
g
h <- as.data.frame(g, row.names = c("a", "b", "c", "d"))
h
arrage(h, V3)
h[sort(h$V2), ]
h <- as.data.frame(g)
h
h <- as.data.frame(g, row.names = c("a", "b", "c", "d", "e"))
h
h[sort(h$V2), ]
h[order(h$V2), ]
sort(h$V2)
h[[V2]][2] <- NA
h[[2]][2] <- NA
h
filter(h, is.na(V2))
subset(h, is.na(V2))
subset(h, !is.na(V2))
h[is.na(h$V2), ]
filter(h, is.na(V2))
h$lp100k <- h |> transform(lp100k = (100 * 3.785 / 1.61) / V4)
h
g <- h |> transform(lp100k = (100 * 3.785 / 1.61) / V4)
g
lp100k <- transform(h, lp100k = (100 * 3.785 / 161) / V4)
h
g <- array(1:3, c(5,4))
h <- as.data.frame(g, row.names = c("a", "b", "c", "d", "e"))
h
lp100k <- transform(h, lp100k = (100 * 3.785 / 161) / V4)
h
lp100k <- mutate(h, lp100k = (100 * 3.785 / 161) / V4)
j <- h |> transform(lp100k = (100 * 3.785 / 1.61) / V4)
j
import dbplyr
lp100k <- dplyr::mutate(h, lp100k = (100 * 3.785 / 1.61) / mpg)
lp100k <- dplyr::mutate(h, lp100k = (100 * 3.785 / 1.61) / V4)
h
lp100k
h$lp100k <- h |> transform(lp100k = (100 * 3.785 / 1.61) / V4)
h
spdata <- read.csv("http://www.stat.ufl.edu/~winner/data/bioequiv_sulf.csv")
spdata.AS <- spdata[measure==2 & drug==1,]
attach(spdata.AS)
spdata <- read.csv("http://www.stat.ufl.edu/~winner/data/bioequiv_sulf.csv")
attach(spdata); names(spdata)
spdata
spdata.AS <- spdata[measure==2 & drug==1,]
detach(spdata)
attach(spdata.AS)
AUC.sulf <- y[measure==2 & drug==1]    # measure=AUC, drug=sulfadoxine
form.AUC.sulf <- form[measure==2 & drug==1] # form=1 if Test, form=2 if Ref
form.AUC.sulf <- factor(form.AUC.sulf, levels=1:2, labels=c("T","R"))
cbind(form.AUC.sulf, AUC.sulf)
## Side-by-side Boxplots
plot(AUC.sulf ~ form.AUC.sulf, main="Sulfadoxine AUC by Formulation")
source("~/Downloads/hw1_AUC.R")
X <- rep(seq(130,180,10), each = 2)
X <- rep(seq(130,180,10), each = 2)
Y <- c(21.28, 22.11, 16.08, 23.16, 20.67, 19.66, 16.93, 17.62, 18.11, 19.30, 12.76, 11.89)
reg <- lm(Y ~ X)
summary(reg)
beta0 <- reg$coef[1]
beta1 <- reg$coef[2]
Y[1]  ## Q1 part 2
beta0
beta1
Yhat1 <- beta0 + Y[1] * beta1
Yhat1 ## Q1 part 3
X[1]
Yhat1 <- beta0 + X[1] * beta1
Yhat1 ## Q1 part 3
e1 <- Y1 - Yhat1
e1 <- Y[1] - Yhat1
e1
Yhat <- beta0 + X * beta1
sum(Y - Yhat)
Yhat
sum((Y - Yhat)^2)
sse <- sum((fitted(reg) - Y)^2)
sse
sse / 10
SSxx <- sum((X - mean(X))^2)
SSxx
xx
sb1 <- mse / ssxx
X <- rep(seq(130,180,10), each = 2)
Y <- c(21.28, 22.11, 16.08, 23.16, 20.67, 19.66, 16.93, 17.62, 18.11, 19.30, 12.76, 11.89)
reg <- lm(Y ~ X)
summary(reg)
beta0 <- reg$coef[1]
beta1 <- reg$coef[2]
Y[1]  ## Q1 part 2
X[1]
beta0
beta1
Yhat1 <- beta0 + X[1] * beta1
Yhat1 ## Q1 part 3
e1 <- Y[1] - Yhat1
e1 ## Q1 part 4
Yhat <- beta0 + X * beta1
sum((Y - Yhat)^2)
sse <- sum((fitted(reg) - Y)^2)
sse
mse <- sse / 10
ssxx <- sum((X - mean(X))^2)
sb1 <- mse / ssxx
sb1
sb1 <- (mse / ssxx)^(1/2)
sb1
t95 <- qt(0.975, 10)
sb1 <- reg$coef[4]
sb1
sb1 <- reg$coef[3]
sb1
sb1 <- reg$coef[2]
sb1
sb1 <- reg$coef[[4]]
sb1 <- reg$coef[6]
sb1
sb1 <- (mse / ssxx)^(1/2)
b1.LB <- beta1 - t95 * sb1
b1.UB <- beta1 + t95 * sb1
b1.LB
b1.UB
sb0 <- (mse(1/10 + (mean(X)^2)/ssxx))^(1/2)
sb0 <- (mse * (1/10 + (mean(X)^2)/ssxx))^(1/2)
sb0
anova(reg)
sb0 <- (mse * (1/12 + (mean(X)^2)/ssxx))^(1/2)
sb0
b0.LB <- beta0 - t95 * sb0 ## Q4
b0.UB <- beta0 + t95 * sb0 ## Q4
b0.LB
B0.UB
b0.UB
Yhat150 <- beta0 + 150 * beta1
Yhat150
Xbar <- mean(X)
sYhat150 <- (mse * (1/12 + ((150 - Xbar)^2)/ssxx))^(1/2)
sYhat150
Yhat150.LB <- Yhat150 - t95 * sYhat150 ## Q5
Yhat150.UB <- Yhat150 + t95 * sYhat150 ## Q5
Yhat150.LB
Yhat150.UB
spred150 <- (mse * (1 + 1/12 + ((150 - Xbar)^2)/ssxx))^(1/2)
pred150.LB <- Yhat150 - t95 * spred150 ## Q6
pred150.UB <- Yhat150 + t95 * spred150 ## Q6
pred150.LB
pred150.UB
corr(Y ~ X)
cor(Y ~ X)
cor(X, Y)
r <- cor(X, Y)
r^2
cor.test(X, Y)
t95
library(mvtnorm)
install.packages("mvtnorm", repos="http://R-Forge.R-project.org")
library(mvtnorm)
library(e1071)
library(class)
## sample size and covariate dimension ranges
nVec = c(100,500,1000,3000)
pVec = c(1,3,5,10,15,20,25,30,40,50,75,100)
## store results
ratio = matrix(NA, length(pVec), length(nVec))
for (ni in 1 : length(nVec)) {
for (pi in 1 : length(pVec)) {
n = nVec[ni]
p = pVec[pi]
## generate covariate matrix
x = matrix(rnorm(n*p), n, p)
## get distances between all pairs of points
distMat = as.matrix(dist(x))
## extract just upper triangle entries to avoid repeats
distances = as.vector(distMat[which(upper.tri(distMat) == TRUE)])
minDist = min(distances)
maxDist = max(distances)
## store ratio of max to min
ratio[pi,ni] = maxDist / minDist
}
}
## plot the effect of p on this ratio for different sample sizes
plot(pVec, ratio[,1], type="l", ylim=c(1,50), lwd=3,
xlab = "# of covariates", ylab="Ratio")
lines(pVec, ratio[,2], lwd=3, col=2)
lines(pVec, ratio[,3], lwd=3, col=3)
lines(pVec, ratio[,4], lwd=3, col=4)
abline(h = 1, lty=2, lwd=2)
legend("topright", paste("n =", nVec), col=1:4, lwd=3, lty=1)
## Can also look at the histogram of differences
n = 500
p = 5
x = matrix(rnorm(n*p), n, p)
## get distances between all pairs of points
distMat = as.matrix(dist(x))
## extract just upper triangle entries to avoid repeats
distances = as.vector(distMat[which(upper.tri(distMat) == TRUE)])
hist(distances)
## More predictors now
n = 500
p = 2500
x = matrix(rnorm(n*p), n, p)
## get distances between all pairs of points
distMat = as.matrix(dist(x))
## extract just upper triangle entries to avoid repeats
distances = as.vector(distMat[which(upper.tri(distMat) == TRUE)])
hist(distances)
## Now see what happens if we do dimension reduction
set.seed(2)
n = 1000
p = 200
x = matrix(rnorm(n*p), n, p)
## true regression function
f = function(x) {
return(-1.5 + exp(x[,1]) + 2*x[,2] - log(x[,3]^2))
}
## generate outcome
y = rbinom(n, 1, p = pnorm(f(x)))
## generate testing data
xtest = matrix(rnorm(500*p), 500, p)
ytest = rbinom(n, 1, p = pnorm(f(xtest)))
## Find the 5 covariates with largest correlation with y
keep = order(abs(cor(y, x)), decreasing=TRUE)[1:5]
x2 = x[,keep]
xtest2 = xtest[,keep]
## run knn on full set
knnMod = knn(train=x, test=xtest, k=10, cl=y)
knnPred = as.numeric(as.character(knnMod))
## compare predictions with truth
mean(knnPred != ytest)
## now run only on the chosen covariates
knnMod5 = knn(train=x2, test=xtest2, k=10, cl=y)
knnPred5 = as.numeric(as.character(knnMod5))
## compare predictions with truth
mean(knnPred5 != ytest)
## now run on the true set of covariates
x3  = x[,1:3]
xtest3 = xtest[,1:3]
knnModTrue = knn(train=x3, test=xtest3, k=10, cl=y)
knnPredTrue = as.numeric(as.character(knnModTrue))
## compare predictions with truth
mean(knnPredTrue != ytest)
library(tree)
library(tree)
library(randomForest)
install.packages("randomForest")
library(randomForest)
library("randomForest")
## Finding correlation matrix
library(dplyr)
## Finding correlation matrix
library(dplyr)
library(stringr)
setwd("~/Documents/COP3530/Project3_43")
dat <- read.csv("csv/tracks_features.csv")
dat <- read.csv("csv/cleaned_tracks.csv")
names(dat)
remove <- c("X", "id", "name", "album",
"album_id", "artists", "artists_id",
"tempo", "year")
dat <- dat[,!(names(dat) %in% remove)]
corr(dat)
head(dat)
remove <- c("X", "id", "name", "album",
"album_id", "artists", "artists_ids",
"tempo", "year")
dat <- dat[,!(names(dat) %in% remove)]
head(dat)
remove <- c("X", "id", "name", "album",
"album_id", "artists", "artist_ids",
"tempo", "year")
dat <- dat[,!(names(dat) %in% remove)]
head(dat)
## sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
res <- cor(dat)
res
write.csv(res, file="csv/corr_matrix.csv")
means <- colMeans(dat)
means
write.csv(means, file="csv/means.csv")
library(matlib)
library(MASS)
library(MASS)
ginv(means)
ginv(res)
res
res <-ginv(res)
res
write.csv(res, file="csv/corr_matrix.csv")
## sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
res <- cov(dat)
res <-ginv(res)
res
## sthda.com/english/wiki/correlation-matrix-a-quick-start-guide-to-analyze-format-and-visualize-a-correlation-matrix-using-r-software
res <- cov(dat)
res
res <-ginv(res)
res
write.csv(res, file="csv/cov_matrix.csv")
